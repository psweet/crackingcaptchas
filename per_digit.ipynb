{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from captcha.image import ImageCaptcha\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Location\n",
    "PATH = './per_digit_model.pth'\n",
    "\n",
    "include_lowercase = False\n",
    "\n",
    "list_of_characters = string.ascii_uppercase + string.digits\n",
    "if include_lowercase:\n",
    "    list_of_characters += string.ascii_lowercase\n",
    "\n",
    "# Data generation\n",
    "num_of_loops = 1000\n",
    "string_length = 5\n",
    "image_width = 100 * string_length\n",
    "image_height = 70\n",
    "max_samples_per_char = int((num_of_loops * string_length) * 0.95)\n",
    "standard_captcha = ImageCaptcha(width=image_width, height=image_height)\n",
    "\n",
    "# Training variables\n",
    "train_pct = 0.8\n",
    "training_epochs = 25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a CAPTCHAs to create a training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_captchas = {}\n",
    "for loop in range(num_of_loops):\n",
    "    loop_str = f\"{loop+1:02}\"\n",
    "\n",
    "    for char in list_of_characters:\n",
    "        # Generate Captcha\n",
    "        captcha_text = f\"{char}  \" * string_length\n",
    "        captcha_image = standard_captcha.generate_image(captcha_text)\n",
    "        solution = captcha_text.replace('  ', '')\n",
    "\n",
    "        # Save the captcha in memory\n",
    "        if generated_captchas.get(solution):\n",
    "            generated_captchas[solution].append(captcha_image)\n",
    "        else:\n",
    "            generated_captchas[solution] = [captcha_image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_captchas(captchas: dict, number: int = 3):\n",
    "    captcha_list = list(captchas.keys())\n",
    "    for solution in captcha_list[:number]:\n",
    "        plt.imshow(captchas[solution][0])\n",
    "        plt.title(solution)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_captchas(generated_captchas, number=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising and Splitting\n",
    "Separate the 5 same string captchas into individual digits and denoise them to create our final training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_captcha(captchas: dict):\n",
    "    processed_captchas = {}\n",
    "\n",
    "    for solution in list(captchas.keys()):\n",
    "        for captcha in captchas[solution]:\n",
    "            # Convert to grayscale then B/W\n",
    "            img = cv.cvtColor(np.array(captcha), cv.COLOR_BGR2GRAY)\n",
    "            _, binarized = cv.threshold(img, 230, 255, cv.THRESH_BINARY_INV)\n",
    "\n",
    "            # Remove pixels with erosion to weaken noise\n",
    "            kernel = np.ones((3, 3), np.uint8)\n",
    "            eroded = cv.erode(binarized, kernel, iterations=1)\n",
    "\n",
    "            # Remove pixels with a median filter to weaken vertical and horizontal lines\n",
    "            median_filtered = cv.medianBlur(eroded, 3)\n",
    "            horizontal_kernel = np.ones((1, 5), np.uint8)\n",
    "            horizontal_filtered = cv.morphologyEx(median_filtered, cv.MORPH_CLOSE, horizontal_kernel)\n",
    "\n",
    "            # Add pixels with dilation to thicken letters and digits\n",
    "            dilation_kernel = np.ones((3, 3), np.uint8)\n",
    "            dilated = cv.dilate(horizontal_filtered, dilation_kernel, iterations=1)\n",
    "\n",
    "            # Remove pixels with a median filter again for good measure\n",
    "            result = cv.medianBlur(dilated, 3)\n",
    "\n",
    "            # Save result in memory\n",
    "            if processed_captchas.get(solution):\n",
    "                processed_captchas[solution].append(result)\n",
    "            else:\n",
    "                processed_captchas[solution] = [result]\n",
    "                \n",
    "    return processed_captchas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample of the denoised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_captchas = denoise_captcha(generated_captchas)\n",
    "show_captchas(processed_captchas, number=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_captchas(captchas: dict):\n",
    "    final_captchas = {}\n",
    "    for solution in list(captchas.keys()):\n",
    "        for captcha in captchas[solution]:\n",
    "            contours, _ = cv.findContours(captcha, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "            filtered_contours = [\n",
    "                contour for contour in contours if cv.contourArea(contour) > 100\n",
    "            ]\n",
    "            \n",
    "            # Sort contours from left to right and only keep the specified number\n",
    "            filtered_contours = sorted(filtered_contours, key=lambda contour: cv.boundingRect(contour)[0])\n",
    "            num_contours = min(len(filtered_contours), string_length)\n",
    "            \n",
    "            # Initialize a black background for the output\n",
    "            segmented_canvas = np.zeros((50, 50 * num_contours), dtype=np.uint8)\n",
    "            \n",
    "            for i, contour in enumerate(filtered_contours[:num_contours]):\n",
    "                x, y, w, h = cv.boundingRect(contour)\n",
    "                \n",
    "                # Calculate the aspect ratio\n",
    "                aspect_ratio = w / h\n",
    "                \n",
    "                # Calculate new width and height to maintain aspect ratio within 50x50 canvas\n",
    "                new_width = min(50, int(aspect_ratio * 50))\n",
    "                new_height = min(50, int(50 / aspect_ratio))\n",
    "                \n",
    "                # Resize the character to the calculated size and place on the black background\n",
    "                character = captcha[y: y+h, x: x+w]\n",
    "                resized_character = cv.resize(character, (new_width, new_height))\n",
    "                x_offset = (50 - new_width) // 2\n",
    "                y_offset = (50 - new_height) // 2\n",
    "                segmented_canvas[y_offset: y_offset+new_height, i * 50 + x_offset : i * 50 + x_offset + new_width] = resized_character\n",
    "\n",
    "            # Save result in memory\n",
    "            if final_captchas.get(solution):\n",
    "                final_captchas[solution].append(segmented_canvas)\n",
    "            else:\n",
    "                final_captchas[solution] = [segmented_canvas]\n",
    "\n",
    "    return final_captchas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_captchas = preprocess_captchas(processed_captchas)\n",
    "show_captchas(final_captchas, number=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data for our final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_captchas(captchas: dict):\n",
    "    dataset = {}\n",
    "    for solution in list(captchas.keys()):\n",
    "        for captcha in captchas[solution]:\n",
    "            sub_images = [captcha[:, i * 50 : (i + 1) * 50] for i in range(captcha.shape[1] // 50)]\n",
    "            char = solution[0]\n",
    "\n",
    "            if len(dataset.get(char, [])) >= max_samples_per_char:\n",
    "                continue\n",
    "\n",
    "            for img in sub_images:\n",
    "                if len(dataset.get(char, [])) >= max_samples_per_char:\n",
    "                    break\n",
    "\n",
    "                if dataset.get(char):\n",
    "                    dataset[char].append(img)\n",
    "                else:\n",
    "                    dataset[char] = [img]\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = split_captchas(final_captchas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize a small sample of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 5\n",
    "num_columns = len(dataset.keys())\n",
    "fig, axes = plt.subplots(num_rows, num_columns, figsize=(num_columns * 1.5, num_rows * 1.5))\n",
    "\n",
    "for col_idx, (character, images) in enumerate(dataset.items()):\n",
    "    for row_idx, image in enumerate(images[:num_rows]):\n",
    "        ax = axes[row_idx, col_idx]\n",
    "        ax.imshow(image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_name(class_index: int):\n",
    "    return list(dataset.keys())[class_index]\n",
    "\n",
    "def get_class_index(class_name: str):\n",
    "    return list(dataset.keys()).index(class_name)\n",
    "    \n",
    "number_of_classes = len(dataset.keys())\n",
    "classes = {\n",
    "    get_class_name(x) : x for x in range(number_of_classes)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratedDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(np.array(image))\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "data_transform = T.Compose(\n",
    "    [\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.5,), (0.5,))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train/test Split\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for char, images in dataset.items():\n",
    "    random.shuffle(images)\n",
    "    cut = int(train_pct * len(images))\n",
    "    train_data += images[:cut]\n",
    "    test_data += images[cut:]\n",
    "    train_labels.append([get_class_index(char) for _ in range(len(images[:cut]))])\n",
    "    test_labels.append([get_class_index(char) for _ in range(len(images[cut:]))])\n",
    "\n",
    "train_labels = np.array(train_labels).flatten()\n",
    "test_labels = np.array(test_labels).flatten()\n",
    "\n",
    "train_dataset = GeneratedDataset(\n",
    "    torch.FloatTensor(train_data),\n",
    "    torch.LongTensor(train_labels),\n",
    "    transform=data_transform\n",
    ")\n",
    "\n",
    "test_dataset = GeneratedDataset(\n",
    "    torch.FloatTensor(test_data),\n",
    "    torch.LongTensor(test_labels),\n",
    "    transform=data_transform\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 12 * 12, 128)\n",
    "        self.fc2 = nn.Linear(128, 36)\n",
    "        self.fc3 = nn.Linear(36, number_of_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(training_epochs):\n",
    "\n",
    "    net.train()\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        print(f\"Epoch {epoch + 1} - Loss: {loss:.4f} - Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "plt.imshow(\n",
    "    np.transpose(\n",
    "        torchvision.utils.make_grid(images).numpy(), (1, 2, 0)\n",
    "    )\n",
    ")\n",
    "print('TrueLabel: ', ' '.join(get_class_name(label) for label in labels))\n",
    "\n",
    "outputs = net(images)\n",
    "_, predicted_labels = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(get_class_name(label) for label in predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per class prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = {classname: 0 for classname in classes.keys()}\n",
    "total_pred = {classname: 0 for classname in classes.keys()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[get_class_name(label)] += 1\n",
    "            total_pred[get_class_name(label)] += 1\n",
    "\n",
    "\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting random CAPTCHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_captcha(length: int = 5):\n",
    "    captcha_char_string = ' '.join(random.choice(list_of_characters) for _ in range(length))\n",
    "    solution = captcha_char_string.replace(\" \", \"\")\n",
    "\n",
    "    image_width = 100 * length\n",
    "    image_height = 70\n",
    "\n",
    "    captcha = ImageCaptcha(width=image_width, height=image_height)\n",
    "    captcha_image = captcha.generate_image(captcha_char_string)\n",
    "\n",
    "    return captcha_image, solution\n",
    "\n",
    "for _ in range(3):\n",
    "    captcha, solution = get_random_captcha()\n",
    "    plt.imshow(captcha)\n",
    "    plt.axis('off')\n",
    "    plt.title(solution)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing and predicting generated CAPTCHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captcha, solution = get_random_captcha()\n",
    "captcha_dict = {solution: [captcha]}\n",
    "\n",
    "denoised = denoise_captcha(captcha_dict)\n",
    "processed = preprocess_captchas(denoised)\n",
    "split = split_captchas(processed)\n",
    "with torch.no_grad():\n",
    "    digits = []\n",
    "\n",
    "    for digit in list(split.values())[0]:\n",
    "        new_digit = digit[np.newaxis, :, :]\n",
    "        digits.append(new_digit)\n",
    "\n",
    "    digits = torch.Tensor(np.array(digits))\n",
    "    prediction = []\n",
    "    outputs = net(digits)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predicted = ''.join(get_class_name(label) for label in predicted)\n",
    "\n",
    "plt.imshow(captcha)\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Actual: {solution} | Predicted:  {predicted}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating performance over X number of CAPTCHAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "number_of_captchas = 10_000\n",
    "for _ in range(number_of_captchas):\n",
    "    captcha, solution = get_random_captcha()\n",
    "    captcha_dict = {solution: [captcha]}\n",
    "\n",
    "    denoised = denoise_captcha(captcha_dict)\n",
    "    processed = preprocess_captchas(denoised)\n",
    "    split = split_captchas(processed)\n",
    "    with torch.no_grad():\n",
    "        digits = []\n",
    "\n",
    "        for digit in list(split.values())[0]:\n",
    "            new_digit = digit[np.newaxis, :, :]\n",
    "            digits.append(new_digit)\n",
    "\n",
    "        digits = torch.Tensor(np.array(digits))\n",
    "        prediction = []\n",
    "        outputs = net(digits)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted = ''.join(get_class_name(label) for label in predicted)\n",
    "    \n",
    "    if predicted.upper() == solution.upper():\n",
    "        correct += 1\n",
    "\n",
    "print(f\"Total: {number_of_captchas}. Correct: {correct}. Accuracy {correct/number_of_captchas:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
