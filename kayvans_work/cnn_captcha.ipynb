{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms as T\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "all_characters= list(string.digits) + list(string.ascii_lowercase) \n",
    "\n",
    "print(all_characters)\n",
    "\n",
    "nchar = len(all_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "current_directory = Path.cwd()\n",
    "\n",
    "# Get the parent directory (one level up)\n",
    "parent_directory = current_directory.parent\n",
    "    \n",
    "path_to_dataset =str(parent_directory)+'/captcha_dataset'\n",
    "\n",
    "captchas = os.listdir(path_to_dataset)\n",
    "\n",
    "X = np.zeros((len(captchas), 50, 200, 1))\n",
    "\n",
    "y_strings = [] \n",
    "\n",
    "for i,img_name in enumerate(captchas):\n",
    "    y_strings.append(img_name[:5])\n",
    "\n",
    "    new_path = path_to_dataset + '/' + captchas[i]\n",
    "\n",
    "    image = Image.open(new_path)\n",
    "\n",
    "    array_image = np.array(image) / 255\n",
    "    \n",
    "    array_image = np.reshape(array_image[:,:,0], (50, 200, 1))\n",
    "\n",
    "    X[i]=(array_image)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make label array\n",
    "\n",
    "y = np.zeros((5 , len(captchas) , nchar)) #5*1070*36\n",
    "# digit * picture * digit label\n",
    "\n",
    "\n",
    "for i,captcha in enumerate(y_strings):\n",
    "   \n",
    "    temp_label =np.zeros((5,nchar))\n",
    "\n",
    "    for j, character in enumerate(captcha):\n",
    "     \n",
    "        character_index =  all_characters.index(character)\n",
    "\n",
    "        temp_label[j,character_index] = 1\n",
    "        \n",
    "    y[:,i,:] = temp_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptchaModel(nn.Module):\n",
    "    def __init__(self, nchar):\n",
    "        super(CaptchaModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.mp1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.mp2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(32)\n",
    "        self.mp3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        self.fc_shared = nn.Linear(4800, 64)\n",
    "        self.fc_outputs = nn.ModuleList([nn.Linear(64, nchar) for _ in range(5)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.mp1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.mp2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.mp3(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        \n",
    "        x = self.fc_shared(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        \n",
    "        outputs = [output_layer(x) for output_layer in self.fc_outputs]\n",
    "        return outputs\n",
    "\n",
    "\n",
    "model = CaptchaModel(nchar)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Convert your data and labels to PyTorch tensors\n",
    "X_tensor = torch.FloatTensor(X.transpose(0, 3, 1, 2))\n",
    "y_tensor = torch.LongTensor(y) \n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train = X_tensor[:round(1070*.8)]\n",
    "y_train = y_tensor[:,:round(1070*.8),:]\n",
    "\n",
    "X_val = X_tensor[round(1070*.8):]\n",
    "y_val =y_tensor[:,round(1070*.8):,:]\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train[0], y_train[1], y_train[2], y_train[3], y_train[4])\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(X_val, y_val[0], y_val[1], y_val[2], y_val[3], y_val[4])\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] - Loss: 17.090244999638312\n",
      "Epoch [2/100] - Loss: 14.429562709949634\n",
      "Epoch [3/100] - Loss: 12.572558579621491\n",
      "Epoch [4/100] - Loss: 11.18979478765417\n",
      "Epoch [5/100] - Loss: 10.028171821876809\n",
      "Epoch [6/100] - Loss: 8.972186971593786\n",
      "Epoch [7/100] - Loss: 8.081206074467412\n",
      "Epoch [8/100] - Loss: 7.257201724582249\n",
      "Epoch [9/100] - Loss: 6.641454573030825\n",
      "Epoch [10/100] - Loss: 6.098852281217222\n",
      "Epoch [11/100] - Loss: 5.454091584240949\n",
      "Epoch [12/100] - Loss: 4.587676966631854\n",
      "Epoch [13/100] - Loss: 3.9382301259923866\n",
      "Epoch [14/100] - Loss: 3.530158457932649\n",
      "Epoch [15/100] - Loss: 3.183662101074501\n",
      "Epoch [16/100] - Loss: 2.853037401481911\n",
      "Epoch [17/100] - Loss: 2.477067894405789\n",
      "Epoch [18/100] - Loss: 2.099965965306317\n",
      "Epoch [19/100] - Loss: 1.9440737830268011\n",
      "Epoch [20/100] - Loss: 1.710588022514626\n",
      "Epoch [21/100] - Loss: 1.3914876138722454\n",
      "Epoch [22/100] - Loss: 1.2349813249376085\n",
      "Epoch [23/100] - Loss: 1.0774433656975075\n",
      "Epoch [24/100] - Loss: 0.9899191039579885\n",
      "Epoch [25/100] - Loss: 0.8741228050655789\n",
      "Epoch [26/100] - Loss: 0.7186542440343786\n",
      "Epoch [27/100] - Loss: 0.6052326239921428\n",
      "Epoch [28/100] - Loss: 0.4932925480383414\n",
      "Epoch [29/100] - Loss: 0.3729127314355638\n",
      "Epoch [30/100] - Loss: 0.3244650849589595\n",
      "Epoch [31/100] - Loss: 0.2989948204270116\n",
      "Epoch [32/100] - Loss: 0.25863339172469246\n",
      "Epoch [33/100] - Loss: 0.24746004574828678\n",
      "Epoch [34/100] - Loss: 0.1862153766883744\n",
      "Epoch [35/100] - Loss: 0.15119141974934824\n",
      "Epoch [36/100] - Loss: 0.1287319000672411\n",
      "Epoch [37/100] - Loss: 0.10596462063215396\n",
      "Epoch [38/100] - Loss: 0.07339194272127417\n",
      "Epoch [39/100] - Loss: 0.04704642019889973\n",
      "Epoch [40/100] - Loss: 0.03472985134080604\n",
      "Epoch [41/100] - Loss: 0.02792541192913497\n",
      "Epoch [42/100] - Loss: 0.025449842697492352\n",
      "Epoch [43/100] - Loss: 0.023828473218061304\n",
      "Epoch [44/100] - Loss: 0.022445783881401574\n",
      "Epoch [45/100] - Loss: 0.021262029151397722\n",
      "Epoch [46/100] - Loss: 0.02019504230055544\n",
      "Epoch [47/100] - Loss: 0.019229851835579785\n",
      "Epoch [48/100] - Loss: 0.018342715722543222\n",
      "Epoch [49/100] - Loss: 0.017524444015213737\n",
      "Epoch [50/100] - Loss: 0.016774838065935507\n",
      "Epoch [51/100] - Loss: 0.01606905719058381\n",
      "Epoch [52/100] - Loss: 0.015408062065641085\n",
      "Epoch [53/100] - Loss: 0.014787943826781379\n",
      "Epoch [54/100] - Loss: 0.014208340913885169\n",
      "Epoch [55/100] - Loss: 0.013668121839011158\n",
      "Epoch [56/100] - Loss: 0.01315958249486155\n",
      "Epoch [57/100] - Loss: 0.01267910895317241\n",
      "Epoch [58/100] - Loss: 0.012227108512349703\n",
      "Epoch [59/100] - Loss: 0.011795018851343129\n",
      "Epoch [60/100] - Loss: 0.011388547252863646\n",
      "Epoch [61/100] - Loss: 0.011002727059854401\n",
      "Epoch [62/100] - Loss: 0.010635718151375099\n",
      "Epoch [63/100] - Loss: 0.01028648955333564\n",
      "Epoch [64/100] - Loss: 0.009951176777206085\n",
      "Epoch [65/100] - Loss: 0.009631164475447603\n",
      "Epoch [66/100] - Loss: 0.009325037986316063\n",
      "Epoch [67/100] - Loss: 0.00903481365767894\n",
      "Epoch [68/100] - Loss: 0.008756568655371666\n",
      "Epoch [69/100] - Loss: 0.008488351548159564\n",
      "Epoch [70/100] - Loss: 0.008227538386428798\n",
      "Epoch [71/100] - Loss: 0.007977900871386131\n",
      "Epoch [72/100] - Loss: 0.0077402436657360305\n",
      "Epoch [73/100] - Loss: 0.00751225700325988\n",
      "Epoch [74/100] - Loss: 0.007293925827576054\n",
      "Epoch [75/100] - Loss: 0.00708396731082488\n",
      "Epoch [76/100] - Loss: 0.006881900269676138\n",
      "Epoch [77/100] - Loss: 0.006688823992455447\n",
      "Epoch [78/100] - Loss: 0.006502117573594053\n",
      "Epoch [79/100] - Loss: 0.0063213077115101945\n",
      "Epoch [80/100] - Loss: 0.006146581800378583\n",
      "Epoch [81/100] - Loss: 0.0059780721914851\n",
      "Epoch [82/100] - Loss: 0.0058168805963187305\n",
      "Epoch [83/100] - Loss: 0.0056613123527279605\n",
      "Epoch [84/100] - Loss: 0.005511422132797263\n",
      "Epoch [85/100] - Loss: 0.005365767912870204\n",
      "Epoch [86/100] - Loss: 0.0052267884990821285\n",
      "Epoch [87/100] - Loss: 0.0050914811867254755\n",
      "Epoch [88/100] - Loss: 0.004960891609597538\n",
      "Epoch [89/100] - Loss: 0.004834288567373598\n",
      "Epoch [90/100] - Loss: 0.004711687487239639\n",
      "Epoch [91/100] - Loss: 0.004593302012869605\n",
      "Epoch [92/100] - Loss: 0.004479491677894084\n",
      "Epoch [93/100] - Loss: 0.004368646449788853\n",
      "Epoch [94/100] - Loss: 0.004262105311715492\n",
      "Epoch [95/100] - Loss: 0.004159037222119945\n",
      "Epoch [96/100] - Loss: 0.004058041273512774\n",
      "Epoch [97/100] - Loss: 0.0039610616103918465\n",
      "Epoch [98/100] - Loss: 0.0038663768899385577\n",
      "Epoch [99/100] - Loss: 0.003775229056676229\n",
      "Epoch [100/100] - Loss: 0.003686416187082176\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 100  # Number of training epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Iterate over batches of the training dataset\n",
    "    for inputs, target0, target1, target2, target3, target4 in train_loader:\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Calculate the loss for each output and sum them up\n",
    "        targets = [target0, target1, target2, target3, target4]\n",
    "        losses = [criterion(output, target.float()) for output, target in zip(outputs, targets)]\n",
    "        loss = sum(losses)\n",
    "\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the model's parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Print the average loss for this epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {running_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 5.79%\n"
     ]
    }
   ],
   "source": [
    "# correct = 0\n",
    "# total = 0\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "#     for inputs, target0, target1, target2, target3, target4 in test_loader:  # Assuming test_loader is your DataLoader\n",
    "#         outputs = model(inputs)\n",
    "        \n",
    "#         # Calculate accuracy for each character\n",
    "#         for output, target in zip(outputs, [target0, target1, target2, target3, target4]):\n",
    "#             predicted = output.argmax(dim=1)  # Get the index of the highest predicted value\n",
    "#            # predicted_labels[:, i] = predicted.numpy()\n",
    "        \n",
    "#             for i,j in enumerate(predicted):\n",
    "                \n",
    "#                 if target[i][j] == 1:\n",
    "#                     correct += 1\n",
    "#                 total += 1\n",
    "\n",
    "# # Calculate overall accuracy\n",
    "# accuracy = correct / total\n",
    "# print(f\"Accuracy: {accuracy:.2%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets predicted labels from test dataset\n",
    "pred_labels = torch.zeros((len(X_val),5,1))\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "\n",
    "    for i,input in enumerate(X_val):\n",
    "        \n",
    "        temp_labels = torch.zeros((5,1))\n",
    "\n",
    "        outputs = model(input.unsqueeze(0))\n",
    "\n",
    "        for j,num in enumerate(outputs):\n",
    "            #print(num.argmax(dim=1)[0])\n",
    "            temp_labels[j] = num.argmax(dim=1)\n",
    "\n",
    "        pred_labels[i] = temp_labels        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn labels into indexes to compare to predicted\n",
    "y_test_indexes = torch.zeros((214,5,1))\n",
    "\n",
    "for i in range(214):\n",
    "\n",
    "    temp_label = torch.zeros((5,1))\n",
    "    #print(y_val[:,i].size())\n",
    "\n",
    "    for j in range(5):\n",
    "\n",
    "        itemindex = np.where(y_val[:,i][j] == 1 )[0][0]\n",
    "\n",
    "        temp_label[j] = itemindex\n",
    "\n",
    "    y_test_indexes[i] = temp_label\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.887850467289718\n"
     ]
    }
   ],
   "source": [
    "# check for entire captchas correctly labeled\n",
    "\n",
    "entire_correct = 0\n",
    "entire_total =0 \n",
    "for i in range(y_val.size()[1]):\n",
    "    a = y_test_indexes[i] ==pred_labels[i]\n",
    "    #print(a)\n",
    "\n",
    "    if False not in a:\n",
    "\n",
    "        entire_correct +=1\n",
    "\n",
    "        entire_total+=1\n",
    "        \n",
    "    else:\n",
    "        entire_total+=1\n",
    "\n",
    "print(entire_correct/entire_total * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.82242990654206\n"
     ]
    }
   ],
   "source": [
    "# check how many digits correctly labeled\n",
    "\n",
    "digits_correct = 0\n",
    "total_digits = 0\n",
    "\n",
    "for i in range(y_val.size()[1]):\n",
    "\n",
    "    for j in range(5):\n",
    "\n",
    "        if y_test_indexes[i][j] ==pred_labels[i][j]:\n",
    "            digits_correct +=1\n",
    "            total_digits +=1\n",
    "\n",
    "        else:\n",
    "            total_digits += 1 \n",
    "    \n",
    "\n",
    "print(digits_correct/total_digits * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
