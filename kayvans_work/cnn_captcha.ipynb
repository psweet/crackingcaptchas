{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms as T\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "all_characters= list(string.digits) + list(string.ascii_lowercase) \n",
    "\n",
    "print(all_characters)\n",
    "\n",
    "nchar = len(all_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "current_directory = Path.cwd()\n",
    "\n",
    "# Get the parent directory (one level up)\n",
    "parent_directory = current_directory.parent\n",
    "    \n",
    "path_to_dataset =str(parent_directory)+'/captcha_dataset'\n",
    "\n",
    "captchas = os.listdir(path_to_dataset)\n",
    "\n",
    "X = np.zeros((len(captchas), 50, 200, 1))\n",
    "\n",
    "y_strings = [] \n",
    "\n",
    "for i,img_name in enumerate(captchas):\n",
    "    y_strings.append(img_name[:5])\n",
    "\n",
    "    new_path = path_to_dataset + '/' + captchas[i]\n",
    "\n",
    "    image = Image.open(new_path)\n",
    "\n",
    "    array_image = np.array(image) / 255\n",
    "    \n",
    "    array_image = np.reshape(array_image[:,:,0], (50, 200, 1))\n",
    "\n",
    "    X[i]=(array_image)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make label array\n",
    "\n",
    "y = np.zeros((5 , len(captchas) , nchar)) #5*1070*36\n",
    "# digit * picture * digit label\n",
    "\n",
    "\n",
    "for i,captcha in enumerate(y_strings):\n",
    "   \n",
    "    temp_label =np.zeros((5,nchar))\n",
    "\n",
    "    for j, character in enumerate(captcha):\n",
    "     \n",
    "        character_index =  all_characters.index(character)\n",
    "\n",
    "        temp_label[j,character_index] = 1\n",
    "        \n",
    "    y[:,i,:] = temp_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptchaModel(nn.Module):\n",
    "    def __init__(self, nchar):\n",
    "        super(CaptchaModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.mp1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.mp2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(32)\n",
    "        self.mp3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        self.fc_shared = nn.Linear(4800, 64)\n",
    "        self.fc_outputs = nn.ModuleList([nn.Linear(64, nchar) for _ in range(5)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.mp1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.mp2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.mp3(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        \n",
    "        x = self.fc_shared(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        \n",
    "        outputs = [output_layer(x) for output_layer in self.fc_outputs]\n",
    "        return outputs\n",
    "\n",
    "\n",
    "model = CaptchaModel(nchar)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Convert your data and labels to PyTorch tensors\n",
    "X_tensor = torch.FloatTensor(X.transpose(0, 3, 1, 2))\n",
    "y_tensor = torch.LongTensor(y) \n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train = X_tensor[:round(1070*.8)]\n",
    "y_train = y_tensor[:,:round(1070*.8),:]\n",
    "\n",
    "X_val = X_tensor[round(1070*.8):]\n",
    "y_val =y_tensor[:,round(1070*.8):,:]\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train[0], y_train[1], y_train[2], y_train[3], y_train[4])\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(X_val, y_val[0], y_val[1], y_val[2], y_val[3], y_val[4])\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/150] - Loss: 16.80638560542354\n",
      "Epoch [3/150] - Loss: 11.899420596935132\n",
      "Epoch [5/150] - Loss: 9.250252511766222\n",
      "Epoch [7/150] - Loss: 7.114172529291223\n",
      "Epoch [9/150] - Loss: 5.148794845298484\n",
      "Epoch [11/150] - Loss: 3.8545435534583197\n",
      "Epoch [13/150] - Loss: 2.903374883863661\n",
      "Epoch [15/150] - Loss: 2.3081485871915466\n",
      "Epoch [17/150] - Loss: 1.8517224788665771\n",
      "Epoch [19/150] - Loss: 1.1896644013899345\n",
      "Epoch [21/150] - Loss: 0.9452706442938911\n",
      "Epoch [23/150] - Loss: 0.6664199464850955\n",
      "Epoch [25/150] - Loss: 0.5513380688649637\n",
      "Epoch [27/150] - Loss: 0.4702240405259309\n",
      "Epoch [29/150] - Loss: 0.44061260753207737\n",
      "Epoch [31/150] - Loss: 0.422610753664264\n",
      "Epoch [33/150] - Loss: 0.278636464090259\n",
      "Epoch [35/150] - Loss: 0.2123786547669658\n",
      "Epoch [37/150] - Loss: 0.1221839217124162\n",
      "Epoch [39/150] - Loss: 0.06301658317722657\n",
      "Epoch [41/150] - Loss: 0.03661648059884707\n",
      "Epoch [43/150] - Loss: 0.019207957821587723\n",
      "Epoch [45/150] - Loss: 0.016483001238494006\n",
      "Epoch [47/150] - Loss: 0.014829099833689354\n",
      "Epoch [49/150] - Loss: 0.013556196940717873\n",
      "Epoch [51/150] - Loss: 0.012481504050945794\n",
      "Epoch [53/150] - Loss: 0.011554210670982246\n",
      "Epoch [55/150] - Loss: 0.010727351738346947\n",
      "Epoch [57/150] - Loss: 0.009996857114688115\n",
      "Epoch [59/150] - Loss: 0.009335288605480283\n",
      "Epoch [61/150] - Loss: 0.00874008852298613\n",
      "Epoch [63/150] - Loss: 0.008191256387228216\n",
      "Epoch [65/150] - Loss: 0.007702167059674307\n",
      "Epoch [67/150] - Loss: 0.007253728806972504\n",
      "Epoch [69/150] - Loss: 0.0068419632087979056\n",
      "Epoch [71/150] - Loss: 0.006454418741028618\n",
      "Epoch [73/150] - Loss: 0.0061009918270563636\n",
      "Epoch [75/150] - Loss: 0.00577175942318583\n",
      "Epoch [77/150] - Loss: 0.005463669602586715\n",
      "Epoch [79/150] - Loss: 0.005179273688958751\n",
      "Epoch [81/150] - Loss: 0.004917611781921651\n",
      "Epoch [83/150] - Loss: 0.004673098386437805\n",
      "Epoch [85/150] - Loss: 0.004434782175209235\n",
      "Epoch [87/150] - Loss: 0.0042162037506285645\n",
      "Epoch [89/150] - Loss: 0.004010506000162827\n",
      "Epoch [91/150] - Loss: 0.003816991570164208\n",
      "Epoch [93/150] - Loss: 0.0036157151787645286\n",
      "Epoch [95/150] - Loss: 0.003437650847007279\n",
      "Epoch [97/150] - Loss: 0.0032724817800852987\n",
      "Epoch [99/150] - Loss: 0.0031115601649852813\n",
      "Epoch [101/150] - Loss: 0.0029656235387341846\n",
      "Epoch [103/150] - Loss: 0.0028227797054030277\n",
      "Epoch [105/150] - Loss: 0.002691207539842085\n",
      "Epoch [107/150] - Loss: 0.0025661789631057116\n",
      "Epoch [109/150] - Loss: 0.002441874481047745\n",
      "Epoch [111/150] - Loss: 0.0023225705242819255\n",
      "Epoch [113/150] - Loss: 0.0022131906072091726\n",
      "Epoch [115/150] - Loss: 0.0021140880373961947\n",
      "Epoch [117/150] - Loss: 0.0020195887320571477\n",
      "Epoch [119/150] - Loss: 0.001930603973084578\n",
      "Epoch [121/150] - Loss: 0.0018408377913551198\n",
      "Epoch [123/150] - Loss: 0.0017614179178727445\n",
      "Epoch [125/150] - Loss: 0.0016868310566577646\n",
      "Epoch [127/150] - Loss: 0.0016152189863431784\n",
      "Epoch [129/150] - Loss: 0.0015434279770555873\n",
      "Epoch [131/150] - Loss: 0.0014763710787519813\n",
      "Epoch [133/150] - Loss: 0.0014137679978308301\n",
      "Epoch [135/150] - Loss: 0.0013527991336390929\n",
      "Epoch [137/150] - Loss: 0.001296579505799821\n",
      "Epoch [139/150] - Loss: 0.0012427147335579826\n",
      "Epoch [141/150] - Loss: 0.0011914522964852276\n",
      "Epoch [143/150] - Loss: 0.0011428938790534933\n",
      "Epoch [145/150] - Loss: 0.0010970827748274638\n",
      "Epoch [147/150] - Loss: 0.0010532734169693733\n",
      "Epoch [149/150] - Loss: 0.0010120686126389989\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 150  # Number of training epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Iterate over batches of the training dataset\n",
    "    for inputs, target0, target1, target2, target3, target4 in train_loader:\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Calculate the loss for each output and sum them up\n",
    "        targets = [target0, target1, target2, target3, target4]\n",
    "        losses = [criterion(output, target.float()) for output, target in zip(outputs, targets)]\n",
    "        loss = sum(losses)\n",
    "\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the model's parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Print the average loss for this epoch\n",
    "    if epoch %2 ==0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {running_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct = 0\n",
    "# total = 0\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "#     for inputs, target0, target1, target2, target3, target4 in test_loader:  # Assuming test_loader is your DataLoader\n",
    "#         outputs = model(inputs)\n",
    "        \n",
    "#         # Calculate accuracy for each character\n",
    "#         for output, target in zip(outputs, [target0, target1, target2, target3, target4]):\n",
    "#             predicted = output.argmax(dim=1)  # Get the index of the highest predicted value\n",
    "#            # predicted_labels[:, i] = predicted.numpy()\n",
    "        \n",
    "#             for i,j in enumerate(predicted):\n",
    "                \n",
    "#                 if target[i][j] == 1:\n",
    "#                     correct += 1\n",
    "#                 total += 1\n",
    "\n",
    "# # Calculate overall accuracy\n",
    "# accuracy = correct / total\n",
    "# print(f\"Accuracy: {accuracy:.2%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets predicted labels from test dataset\n",
    "pred_labels = torch.zeros((len(X_val),5,1))\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    for i,input in enumerate(X_val):\n",
    "        \n",
    "        temp_labels = torch.zeros((5,1))\n",
    "\n",
    "        outputs = model(input.unsqueeze(0))\n",
    "\n",
    "        for j,num in enumerate(outputs):\n",
    "            #print(num.argmax(dim=1)[0])\n",
    "            temp_labels[j] = num.argmax(dim=1)\n",
    "\n",
    "        pred_labels[i] = temp_labels        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn labels into indexes to compare to predicted\n",
    "y_test_indexes = torch.zeros((214,5,1))\n",
    "\n",
    "for i in range(214):\n",
    "\n",
    "    temp_label = torch.zeros((5,1))\n",
    "    #print(y_val[:,i].size())\n",
    "\n",
    "    for j in range(5):\n",
    "\n",
    "        itemindex = np.where(y_val[:,i][j] == 1 )[0][0]\n",
    "\n",
    "        temp_label[j] = itemindex\n",
    "\n",
    "    y_test_indexes[i] = temp_label\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.355140186915886\n"
     ]
    }
   ],
   "source": [
    "# check for entire captchas correctly labeled\n",
    "\n",
    "entire_correct = 0\n",
    "entire_total =0 \n",
    "for i in range(y_val.size()[1]):\n",
    "    a = y_test_indexes[i] ==pred_labels[i]\n",
    "    #print(a)\n",
    "\n",
    "    if False not in a:\n",
    "\n",
    "        entire_correct +=1\n",
    "\n",
    "        entire_total+=1\n",
    "        \n",
    "    else:\n",
    "        entire_total+=1\n",
    "\n",
    "print(entire_correct/entire_total * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.3177570093458\n"
     ]
    }
   ],
   "source": [
    "# check how many digits correctly labeled\n",
    "\n",
    "digits_correct = 0\n",
    "total_digits = 0\n",
    "\n",
    "for i in range(y_val.size()[1]):\n",
    "\n",
    "    for j in range(5):\n",
    "\n",
    "        if y_test_indexes[i][j] ==pred_labels[i][j]:\n",
    "            digits_correct +=1\n",
    "            total_digits +=1\n",
    "\n",
    "        else:\n",
    "            total_digits += 1 \n",
    "    \n",
    "\n",
    "print(digits_correct/total_digits * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
