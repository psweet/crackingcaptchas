{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms as T\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "current_directory = Path.cwd()\n",
    "\n",
    "# Get the parent directory (one level up)\n",
    "parent_directory = current_directory.parent\n",
    "    \n",
    "    \n",
    "path_to_dataset =str(parent_directory)+'/captcha_dataset'\n",
    "\n",
    "captchas = os.listdir(path_to_dataset)\n",
    "\n",
    "Y = []\n",
    "X = []\n",
    "# png's are 3D and 4D but all dimension are the same execpt for the 4th which is all balck\n",
    "# only turn png into array and keep the first dimension\n",
    "for i,img_name in enumerate(captchas):\n",
    "    Y.append(img_name[:5])\n",
    "\n",
    "    new_path = path_to_dataset + '/' + captchas[i]\n",
    "\n",
    "    image = Image.open(new_path)\n",
    "\n",
    "    array_image = np.array(image) \n",
    "\n",
    "    X.append(array_image[:,:,0])\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "all_characters= list(string.ascii_lowercase) + list(string.digits)\n",
    "\n",
    "print(all_characters)\n",
    "\n",
    "nchar = len(all_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make label array\n",
    "\n",
    "y = np.zeros((5,len(Y),nchar)) #5*1070*36(5 letters in captcha) with all entries 0\n",
    "\n",
    "for i,captcha in enumerate(Y):\n",
    "   \n",
    "  temp_label =np.zeros((5,nchar))\n",
    "\n",
    "  for j, character in enumerate(captcha):\n",
    "     \n",
    "      character_index =  all_characters.index(character)\n",
    "      temp_label[j,character_index] = 1\n",
    "  y[:,i] = temp_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "rand_i = np.random.randint(0,len(Y),size=(n))\n",
    "#362"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_digit(pic,a,b,label,ind):\n",
    "    plt.imshow(pic[:,a:b],cmap='gray')\n",
    "\n",
    "    plt.title(label[ind])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_i = np.random.randint(0,len(Y))\n",
    "\n",
    "pic = X[rand_i][:,30:150]\n",
    "plt.imshow(pic)\n",
    "plt.show()\n",
    "label = Y[rand_i] \n",
    "diffs=[0]\n",
    "\n",
    "large_characters=['w','m']\n",
    "small_characters = ['f','f','1','l','t']\n",
    "\n",
    "small_size= 15\n",
    "normal_size=25\n",
    "large_size= 40\n",
    "for i in range(5):\n",
    "    \n",
    "    if label[i] in large_characters:\n",
    "\n",
    "        show_digit(pic,sum(diffs),sum(diffs)+large_size,label,i)\n",
    "\n",
    "        diffs.append(large_size)\n",
    "    \n",
    "    elif str(label[i]) in small_characters:\n",
    "\n",
    "        show_digit(pic,sum(diffs),sum(diffs)+small_size,label,i)\n",
    "        diffs.append(small_size)\n",
    "\n",
    "    else:\n",
    "        show_digit(pic,sum(diffs),sum(diffs)+normal_size,label,i)\n",
    "        diffs.append(normal_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, imgshape, nchar):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=(3, 3), padding=(1, 1))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.mp1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(3, 3), padding=(1, 1))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.mp2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=(3, 3), padding=(1, 1))\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.mp3 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.dens1 = nn.Linear(32 * 7 * 25, 64) # Calculate the input size based on the shapes\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dens_out = nn.Linear(64, nchar)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.mp1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.mp2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.mp3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.dens1(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        outs = []\n",
    "        for _ in range(5):\n",
    "            x_drop = self.dropout(x)\n",
    "            out = self.dens_out(x_drop)\n",
    "            outs.append(out)\n",
    "\n",
    "        return outs\n",
    "\n",
    "# Define the input shape and number of characters in the output\n",
    "imgshape = (1, 50, 200)\n",
    "nchar = 5  # Replace 10 with the actual number of characters in the output (e.g., the number of classes in the classification task)\n",
    "\n",
    "# Create the model\n",
    "model = CustomModel(imgshape, nchar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EMNIST MODEL\n",
    "<br>\n",
    "https://machinelearningmastery.com/building-a-convolutional-neural-network-in-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import EMNIST\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(in_features=128 * 3 * 3, out_features=512)  # Adjusted input size\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=256)\n",
    "        self.fc3 = nn.Linear(in_features=256, out_features=62)  # 62 classes (10 digits + 52 letters)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 3 * 3)  # Reshape before fully connected layers\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.dropout(torch.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess EMNIST data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = EMNIST(root='./data', split='byclass', train=True, transform=transform, download=True)\n",
    "test_dataset = EMNIST(root='./data', split='byclass', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy on test data: {100 * correct / total:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
