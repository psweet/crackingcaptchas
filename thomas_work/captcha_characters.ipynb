{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "PATH = './emnist.pth'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download/load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip to ./data/EMNIST/raw/gzip.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 561753746/561753746 [00:15<00:00, 37122723.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/EMNIST/raw/gzip.zip to ./data/EMNIST/raw\n"
     ]
    }
   ],
   "source": [
    "transform = T.Compose(\n",
    "    [\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.5), (0.5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "data_set = torchvision.datasets.EMNIST(\n",
    "    root='./data',\n",
    "    split=\"byclass\",\n",
    "    train=True,\n",
    "    download=True, \n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# removing upper case letters\n",
    "uppers = np.arange(10,36)\n",
    "\n",
    "pics = np.array(data_set.data)\n",
    "targets = np.array(data_set.targets)\n",
    "\n",
    "targets_indx = np.arange(len(targets))\n",
    "\n",
    "#stores indexes of corresponding pics of classes\n",
    "new_targets= []\n",
    "\n",
    "for i in range(len(targets)):\n",
    "\n",
    "    if targets[i] not in uppers:\n",
    "        new_targets.append(targets_indx[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pics = pics[new_targets]\n",
    "data_target=targets[new_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum key: 45\n",
      "Minimum amount: 1896\n",
      "min value key: {'j'}\n"
     ]
    }
   ],
   "source": [
    "# classes uneven\n",
    "# finding class with least amount and using that number for all classes\n",
    "frequency_dict = {item: np.count_nonzero(data_target == item) for item in np.unique(data_target)}\n",
    "\n",
    "min_key = min(frequency_dict, key=frequency_dict.get)\n",
    "min_value = frequency_dict[min_key]\n",
    "\n",
    "print(\"Minimum key:\", min_key)\n",
    "print(\"Minimum amount:\", min_value)\n",
    "\n",
    "class_dict = {key: value for key, value in data_set.class_to_idx.items() if key not in list(string.ascii_uppercase)}\n",
    "\n",
    "value = {i for i in class_dict if class_dict[i]==min_key}\n",
    "print(\"min value key:\",value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get even amount of pitures for every class\n",
    "n = min_value\n",
    "u = pd.unique(data_target)\n",
    "\n",
    "class_indexs= {x: [] for x in u}\n",
    "\n",
    "for class_num in u:\n",
    "    for j in range(len(data_target)):\n",
    "        if data_target[j] == class_num and len(class_indexs[class_num]) <n:\n",
    "            class_indexs[class_num].append(j)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_pics= []\n",
    "even_targets = []\n",
    "\n",
    "for key in class_indexs.keys():\n",
    "\n",
    "    for j in range(n):\n",
    "        even_pics.append( data_pics[class_indexs[key][j]] )\n",
    "        even_targets.append( key )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35]\n"
     ]
    }
   ],
   "source": [
    "for i,target in enumerate(even_targets):\n",
    "    if target > 9:\n",
    "        even_targets[i] = target - 26\n",
    "\n",
    "print(np.unique(even_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# c = 0 \n",
    "# for i in Counter(even_targets).keys():\n",
    "\n",
    "#     c+=(Counter(even_targets)[i] - 1896)\n",
    "    \n",
    "# print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(even_pics), np.array(even_targets),\n",
    "                                                     test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fv/nwc5x101553470vxrsy344_40000gn/T/ipykernel_7569/605475821.py:2: DeprecationWarning: This function is deprecated. Please call randint(0, 54604 + 1) instead\n",
      "  n= np.random.random_integers(0,len(y_train))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "U\n"
     ]
    }
   ],
   "source": [
    "# pitures are reflected \n",
    "n= np.random.random_integers(0,len(y_train))\n",
    "n=3\n",
    "plt.imshow( np.transpose(X_train[n]) ,cmap='gray')\n",
    "plt.show()\n",
    "print(y_train[n])\n",
    "\n",
    "for i in data_set.class_to_idx.keys():\n",
    "    if data_set.class_to_idx[i]== y_train[n]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transposeing all pictures\n",
    "transposed_images_tr = np.zeros( [len(y_train), 28, 28] )\n",
    "for i,pic in enumerate(X_train):\n",
    "    transposed_images_tr[i,:,:] = pic.transpose()\n",
    "\n",
    "transposed_images_tst = np.zeros( [len(y_test), 28, 28] )\n",
    "for i,pic in enumerate(X_test):\n",
    "    transposed_images_tst[i,:,:] = pic.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset( torch.Tensor(transposed_images_tr), torch.Tensor(y_train) )\n",
    "test_dataset = TensorDataset( torch.Tensor(transposed_images_tst), torch.Tensor(y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for a,b in trainloader:\n",
    "    print(torch.Tensor.size(b))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "tensor_without_channel = torch.randn(64, 28, 28)\n",
    "\n",
    "# Add a channel dimension using unsqueeze\n",
    "tensor_with_channel = tensor_without_channel.unsqueeze(1)\n",
    "\n",
    "print(tensor_with_channel.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=128 * 3 * 3, out_features=512)  \n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=256)\n",
    "        self.fc3 = nn.Linear(in_features=256, out_features=  36)  # 62 - 26 classes \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 3 * 3)  # Reshape before fully connected layers\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.dropout(torch.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs,labels in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.unsqueeze(1))\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy on test data: {100 * correct / total:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
